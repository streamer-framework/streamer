#bootstrap.servers=10.0.238.12:9092
bootstrap.servers=localhost:9092
#bootstrap.servers=http://kafka:29092

visualization = true

####Producer:
acks=all
retries=0
batch.size=16384
auto.commit.interval.ms=1000
linger.ms=0
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=org.apache.kafka.common.serialization.StringSerializer
block.on.buffer.full=true

containsHeader = true

# The path of the data used in the kdd cup 99 cybersecurity project (online classification algorithm)
datafile = ../data/data_kdd-cup-99/multiclass_classification_kdd_cup_99.csv

### Production Type (ONLINE /OFFLINE)
producerType = OFFLINE

## Production ONLINE
epsilonne = -3000
scale = 1800

## Production OFFLINE (by blocks)
maxBlocks = 1000
recordsPerBlock = 50
producerTimeInterval = 10000


### Production Type (ONLINE /OFFLINE)
producerType = OFFLINE
epsilonne = -3000
scale = 1800

####Launcher:
group.id=test
application.id=test
#enable.auto.commit=true
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
# fast session timeout makes it more fun to play with failover
session.timeout.ms=10000
# These buffer sizes seem to be needed to avoid consumer switching to
# a mode where it processes one bufferful every 5 seconds with multiple
# timeouts along the way.  No idea why this happens.
fetch.min.bytes=50000
receive.buffer.bytes=262144
max.partition.fetch.bytes=2097152

readingTimeInterval = 100
problem.type = KDDClassification
#consumer.prepostprocessor = PrePostProcessorKDDClassification (to be added if needed)
outputTopic = OutputPlatformKDDB

#### Common Params
mainTopic = topic_kddmulticlass